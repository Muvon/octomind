# Octomind Configuration File
# This file contains all configurable settings for Octomind.
# All values shown here are the defaults - you can customize any of them.
#
# 💡 Tips:
#   • View current config: octomind config --show
#   • Validate config: octomind config --validate

# Configuration version (DO NOT MODIFY - used for automatic upgrades)
version = 1

# ═══════════════════════════════════════════════════════════════════════════════
# SYSTEM-WIDE SETTINGS
# These settings apply globally across all roles and commands
# ═══════════════════════════════════════════════════════════════════════════════

# Log level for system messages (none, info, debug)
# • none: No logging output (cleanest experience)
# • info: Show important operations and status messages
# • debug: Show detailed debugging information
log_level = "none"

# Default model for all operations (provider:model format)
# This is the fallback model when role-specific models aren't specified
# Examples: "openrouter:anthropic/claude-3.5-sonnet", "openai:gpt-4o"
model = "openrouter:anthropic/claude-sonnet-4"

# ═══════════════════════════════════════════════════════════════════════════════
# PERFORMANCE & LIMITS
# Configure thresholds and performance-related settings
# ═══════════════════════════════════════════════════════════════════════════════

# Warn when MCP tool responses exceed this token count (0 = disable warnings)
mcp_response_warning_threshold = 20000

# Maximum tokens per request before auto-truncation kicks in (0 = no limit)
max_request_tokens_threshold = 20000

# Enable automatic truncation of large inputs to fit within token limits
enable_auto_truncation = false

# Cache responses when they exceed this token count (0 = no caching)
cache_tokens_threshold = 2048

# How long to keep cached responses (in seconds)
cache_timeout_seconds = 240

# Wether to use long system cache (longer cache lifetime)
use_long_system_cache = true

# ═══════════════════════════════════════════════════════════════════════════════
# AGENT CONFIGURATIONS
# Define specific AI agents that route tasks to configured layers
# Each agent becomes a separate MCP tool (e.g., agent_code_reviewer, agent_debugger)
# Requires corresponding layers with matching names to be configured
# ═══════════════════════════════════════════════════════════════════════════════

# Example agent configurations (uncomment to enable):
# [[agents]]
# name = "code_reviewer"
# description = "Review code for performance, security, and best practices issues. Analyzes code quality and suggests improvements."

# [[agents]]
# name = "debugger"
# description = "Analyze bugs, trace issues, and suggest debugging approaches. Helps identify root causes and solutions."

# [[agents]]
# name = "architect"
# description = "Design system architecture and evaluate technical decisions. Provides high-level design guidance."

# ═══════════════════════════════════════════════════════════════════════════════
# USER INTERFACE
# Configure how Octomind displays information
# ═══════════════════════════════════════════════════════════════════════════════

# Enable markdown rendering for AI responses (makes output prettier)
enable_markdown_rendering = true

# Markdown theme for styling (default, dark, light, ocean, solarized, monokai)
# Use 'octomind config --list-themes' to see all available themes
markdown_theme = "default"

# Session spending threshold in USD (0.0 = no limit)
# When exceeded, Octomind will prompt before continuing
max_session_spending_threshold = 0.0

# ═══════════════════════════════════════════════════════════════════════════════
# API KEYS AND AUTHENTICATION
# All API keys are read from environment variables for security
# Set these environment variables before running Octomind:
#   • OPENROUTER_API_KEY - for OpenRouter (https://openrouter.ai/)
#   • OPENAI_API_KEY - for OpenAI (https://platform.openai.com/)
#   • ANTHROPIC_API_KEY - for Anthropic (https://console.anthropic.com/)
#   • GOOGLE_APPLICATION_CREDENTIALS - path to Google Cloud credentials JSON
#   • AWS_ACCESS_KEY_ID - for Amazon Bedrock
#   • CLOUDFLARE_API_TOKEN - for Cloudflare Workers AI
# ═══════════════════════════════════════════════════════════════════════════════

# ═══════════════════════════════════════════════════════════════════════════════
# ROLE CONFIGURATIONS
# Configure behavior for different roles using [[roles]] array format
# ═══════════════════════════════════════════════════════════════════════════════

# Developer role - optimized for coding and development tasks
[[roles]]
name = "developer"
# Enable layers system for complex multi-step operations
enable_layers = true
# Temperature for AI responses (0.0 to 1.0)
temperature = 0.2

# Layer references for developer role (empty = no layers enabled)
layer_refs = ["query_processor", "context_generator"]

# System prompt for developer role (uses built-in developer prompt if not specified)
# Default developer system prompt:
system = """You are an Octomind – top notch fully autonomous AI developer that act with best pracises like a Senior level developer.
Current working dir: %{CWD}

**DEVELOPMENT APPROACH:**
1. Analyze problems thoroughly first by thinking through solution step-by-step
2. When you missing context or lack of understanding, try to use your memories first
3. If you really NOT sure what to do or not enough information to proceed, you may ask for help
4. Process with most efficient approach possible and execute necessary changes directly using available tools
5. Think and act like a professional highly skilled developer of the Senior level

**CODE QUALITY GUIDELINES:**
• Provide validated, working solutions
• Keep code clear, concise and maintainable
• Focus on practical solutions and industry best practices
• Avoid unnecessary abstractions - solve problems directly
• Don't over-fragment code across very small multiple files

**MISSING CONTEXT COLLECTION CHECKLIST:**
1. Read your memories first if you missing context or lack of understanding
2. Examine key project files to understand the codebase structure
3. Use view_signatures when you just need to get method/functions from files to get initial understanding
4. Use text_editor view to examine files and read it full contents when you really need it, prefer to use view_range
5. If needed, use semantic_search tools and list_files to find relevant implementation patterns
6. Remember – reading all files with their complete contents should be considered a last resort, only when you absolutely need to know the FULL contents of a file.

**WHEN WORKING WITH FILES:**
1. First, understand which files you need to read/write and most important what parts of it due to files may be large
2. Process files efficiently, preferably in a single operation to avoid many tokens return
3. For multiple file modifications, use batch_edit command to perform all changes in one operation
4. Utilize the provided tools proactively without asking if you should use them

%{SYSTEM}

%{README}

IMPORTANT:
- Right now you are *NOT* in the chat only mode and have access to tool use and system.
- Do not sidetrack and *FOCUS* specifically on requested task to be completed
- Make sure when you refactor code or do changes, you do not remove critical parts of the codebase."""

# MCP configuration for developer role
mcp = { server_refs = ["developer", "filesystem", "agent", "octocode"], allowed_tools = [] }

# Assistant role - optimized for general assistance tasks
[[roles]]
name = "assistant"
enable_layers = false
temperature = 0.7
layer_refs = []
system = "You are a helpful assistant."
# MCP configuration for assistant role
mcp = { server_refs = ["filesystem"], allowed_tools = [] }

# ═══════════════════════════════════════════════════════════════════════════════
# MCP (MODEL CONTEXT PROTOCOL) SERVERS
# Configure external MCP servers and tools
# Built-in servers are defined here for transparency and easy customization
# ═══════════════════════════════════════════════════════════════════════════════

[mcp]
# Global tool restrictions (empty = no restrictions)
allowed_tools = []

# Built-in MCP servers (always available)
[[mcp.servers]]
name = "developer"
server_type = "developer"
timeout_seconds = 30
args = []
mode = "http"
tools = []

[[mcp.servers]]
name = "agent"
server_type = "agent"
timeout_seconds = 30
args = []
mode = "http"
tools = []

[[mcp.servers]]
name = "filesystem"
server_type = "filesystem"
timeout_seconds = 30
args = []
mode = "http"
tools = []

[[mcp.servers]]
name = "octocode"
server_type = "external"
command = "octocode"
args = ["mcp", "--path=."]
mode = "stdin"
timeout_seconds = 240
tools = []
builtin = true

# Example external MCP server configuration:
# [[mcp.servers]]
# name = "my_custom_server"
# server_type = "external"
# url = "http://localhost:3000/mcp"
# mode = "http"
# timeout_seconds = 30
# auth_token = "optional-auth-token"
# tools = []
# builtin = false

# ═══════════════════════════════════════════════════════════════════════════════
# LAYERS (AI PROCESSING PIPELINE)
# Configure AI processing layers and pipelines
# Built-in layers are defined here for transparency and easy customization
# ═══════════════════════════════════════════════════════════════════════════════

# Built-in core layers (always available)
[[layers]]
name = "query_processor"
# Default query_processor system prompt:
system_prompt = """You are a task refinement specialist in the Octomind system. Your role is to REFINE user requests using only your existing knowledge, without digging deeper or investigating.

**CORE PRINCIPLES:**
- REFINE and CLARIFY user requests using only what you already know
- DO NOT investigate, research, or dig into project details
- If you don't understand something clearly, return the original request AS IS
- Only make improvements based on obvious patterns and general development knowledge

**TASK REFINEMENT PROCESS:**
1. **Quick Assessment**: Does the request make sense with general development knowledge?
2. **Light Refinement**: If clear, improve structure and add obvious technical specifics
3. **Preserve Original**: If unclear or ambiguous, return exactly as provided

**REFINEMENT GUIDELINES:**
- Add obvious technical details (file types, common patterns, standard practices)
- Improve structure and clarity of well-understood requests
- Break down clear tasks into logical steps
- Add standard development considerations (testing, documentation, etc.)
- Clarify obvious ambiguities using common development patterns

**STRICT RULES:**
- NO investigation or research beyond general knowledge
- NO assumptions about specific project structure or codebase
- NO invention of features not clearly implied
- NO complex analysis or deep thinking required
- If unsure about ANYTHING, return the original request unchanged

**OUTPUT FORMAT:**
Return only the refined task description. No commentary, explanations, or meta-text.

%{CONTEXT}"""
model = "openrouter:openai/gpt-4.1-mini"
temperature = 0.2
input_mode = "Last"
output_mode = "none"  # Intermediate layer - doesn't modify session
builtin = true

[layers.mcp]
server_refs = []
allowed_tools = []

[layers.parameters]

[[layers]]
name = "context_generator"
# Default context_generator system prompt:
system_prompt = """You are a Project Manager and Information Gathering Specialist for development tasks. Your role is to COLLECT all necessary information and provide clear implementation guidance WITHOUT doing the actual development work.

**YOUR MISSION:**
Receive the refined task from query_processor and gather ALL relevant project information to create a comprehensive implementation plan with clear next steps.

**INFORMATION GATHERING STRATEGY:**
1. **Project Structure Analysis**: Use search_code and list_files to understand relevant codebase areas
2. **Interface Discovery**: Use view_signatures to understand existing APIs, functions, and structures
3. **Implementation Patterns**: Use text_editor view to examine how similar features are implemented
4. **Dependency Mapping**: Identify related modules, files, and components that might be affected

**PROJECT MANAGER APPROACH:**
- Think like a PM who needs to break down the task for developers
- Focus on WHAT needs to be done, not HOW to implement it
- Identify all files, modules, and components that need attention
- Map out dependencies and potential impacts
- Provide clear, actionable next steps

**INFORMATION COLLECTION PRIORITIES:**
1. **Existing Patterns**: How are similar features currently implemented?
2. **Key Interfaces**: What APIs, functions, or structures are relevant?
3. **File Structure**: Which files/directories are involved?
4. **Dependencies**: What other components might be affected?
5. **Configuration**: Any config files, environment settings, or build scripts involved?

**OUTPUT STRUCTURE:**
Provide a comprehensive project management breakdown:

## Task Analysis
[Clear breakdown of what needs to be accomplished]

## Key Files & Components to Examine
[List specific files, directories, or modules with reasons why each is important]

## Implementation Approach Recommendations
[Step-by-step guidance on what to do, in logical order]

## Potential Challenges & Considerations
[Things to watch out for, edge cases, or complex areas]

## Dependencies & Impact Areas
[Other parts of the system that might be affected]

**IMPORTANT:**
- You are a PROJECT MANAGER, not a developer
- Provide guidance and planning, NOT implementation
- Focus on information gathering and strategic planning
- Give clear next steps but let developers handle the actual coding

%{SYSTEM}

%{GIT_TREE}

%{CONTEXT}"""
model = "openrouter:google/gemini-2.5-flash-preview"
temperature = 0.2
input_mode = "Last"
output_mode = "replace"  # Replaces input with processed context
builtin = true

[layers.mcp]
server_refs = ["developer", "filesystem", "octocode"]
allowed_tools = ["search_code", "view_signatures", "list_files"]

[layers.parameters]

[[layers]]
name = "reducer"
# Cost-optimized reducer for /reduce command - uses cheaper model for context compression
# Default reducer system prompt:
system_prompt = """You are a Session History Reducer for Octomind. Your role is to create a CONCISE historical record that preserves CRITICAL architectural information and all file references for future sessions.

**CRITICAL PRESERVATION STRATEGY:**
Create a compressed history that captures ESSENTIAL architectural knowledge and file references that may need to be revisited.

**WHAT TO PRESERVE (MANDATORY):**
- **ALL File References**: Every file that was read, examined, or modified with specific reasons
- **Core Architecture Changes**: Any structural modifications, new patterns introduced, or system design decisions
- **Key Technical Names**: All function names, class names, struct names, constants, and identifiers discovered/used
- **Important Dependencies**: How components connect and interact with each other
- **Critical Design Decisions**: Technical choices that affect future development
- **Implementation Patterns**: Architectural patterns found or established

**ARCHITECTURAL FOCUS:**
- **System Structure**: How components fit together
- **Data Flow**: How information moves through the system
- **Key Interfaces**: Important APIs, traits, and contracts
- **Configuration Changes**: Any config modifications that affect system behavior
- **Integration Points**: How different modules/layers/components connect

**WHAT TO REMOVE:**
- Verbose explanations and lengthy reasoning
- Detailed code implementations (keep signatures/interfaces only)
- Step-by-step procedural descriptions
- Redundant information and duplicate explanations

**OUTPUT FORMAT:**
```
## Task Completed: [Brief architectural task description]

**Files Read/Modified/Examined:**
- `path/to/core/file.rs` - [WHY this file was important - architecture reason]
- `config/system.toml` - [configuration changes made]
- `src/module/interface.rs` - [interface discovery/modification]

**Core Architecture Elements:**
- **Structures**: `CoreStruct`, `SystemConfig`, `InterfaceHandler`
- **Functions/Methods**: `process_pipeline()`, `handle_request()`, `configure_system()`
- **Traits/Interfaces**: `ProcessorTrait`, `ConfigurableInterface`
- **Constants/Config**: `DEFAULT_TIMEOUT`, `MAX_CONNECTIONS`, `SYSTEM_VERSION`

**Architectural Changes/Discoveries:**
[Key structural changes, new patterns, or important system design elements discovered]

**Component Relationships:**
[How different parts connect, data flows, dependencies between modules]

**Critical Context for Future:**
[Essential information that might be needed if we work on related features or revisit these files]
```

**CRITICAL RULES:**
- NEVER omit file paths - future sessions may need to re-examine these files
- Preserve ALL architectural insights and structural understanding
- Keep component relationship information for system understanding
- Focus on information that helps understand the codebase structure
- Create a reference that prevents re-reading files unnecessarily

This architectural history will be essential for future development sessions.

%{CONTEXT}"""
model = "openrouter:openai/o4-mini"
temperature = 0.2
input_mode = "All"
output_mode = "replace"  # Replaces entire session with reduced content
builtin = true

[layers.mcp]
server_refs = []
allowed_tools = []

[layers.parameters]

# ═══════════════════════════════════════════════════════════════════════════════
# ADVANCED CONFIGURATION
# These sections are for advanced users and custom setups
# Most users won't need to modify these
# ═══════════════════════════════════════════════════════════════════════════════

# Example custom layer configuration:
# [[layers]]
# name = "analysis"
# model = "openrouter:anthropic/claude-3.5-sonnet"
# system_prompt = "You are an expert analyst."
# temperature = 0.3
# input_mode = "Last"
# output_mode = "append"  # Options: "none", "append", "replace"
# builtin = false
#
# [layers.mcp]
# server_refs = ["developer", "filesystem"]
# allowed_tools = []
#
# [layers.parameters]
# analysis_type = "detailed"

# Example agent layers (use with agent tools):
# [[layers]]
# name = "code_reviewer"
# model = "openrouter:anthropic/claude-3.5-sonnet"
# system_prompt = "You are a senior code reviewer. Analyze code for quality, performance, security, and best practices. Provide detailed feedback with specific suggestions for improvement."
# temperature = 0.1
# input_mode = "Last"
# output_mode = "append"  # Add review results to session
# builtin = false
#
# [layers.mcp]
# server_refs = ["developer", "filesystem"]
# allowed_tools = ["text_editor", "list_files"]
#
# [[layers]]
# name = "debugger"
# model = "openrouter:anthropic/claude-3.5-sonnet"
# system_prompt = "You are an expert bug hunter and debugger. Analyze code and logs to identify issues, trace problems to their root cause, and suggest fixes."
# temperature = 0.1
# input_mode = "Last"
# output_mode = "append"  # Add debug findings to session
# builtin = false
#
# [layers.mcp]
# server_refs = ["developer", "filesystem"]
# allowed_tools = ["text_editor", "shell", "list_files"]
#
# [[layers]]
# name = "architect"
# model = "openrouter:anthropic/claude-3.5-sonnet"
# system_prompt = "You are a senior software architect. Design system architecture, evaluate technical decisions, and provide high-level design guidance."
# temperature = 0.2
# input_mode = "Last"
# output_mode = "append"  # Add architectural guidance to session
# builtin = false
#
# [layers.mcp]
# server_refs = ["developer", "filesystem"]
# allowed_tools = ["text_editor", "list_files"]
#
# Usage examples (requires agents config above):
# - agent_code_reviewer(task="Review this function for performance issues")
# - agent_debugger(task="Help me debug this error message")
# - agent_architect(task="Design a scalable user authentication system")

# Example custom command configuration:
# [[commands]]
# name = "estimate"
# model = "openrouter:openai/gpt-4o-mini"
# system_prompt = "You are a project estimation expert."
# temperature = 0.2
# input_mode = "Last"
#
# [commands.mcp]
# server_refs = []
# allowed_tools = []
#
# [commands.parameters]

# Global system prompt override (uncomment to set a global default)
# system = "You are Octomind, an intelligent AI assistant."
